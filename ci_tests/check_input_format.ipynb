{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from ibm_watson_studio_pipelines import WSPipelines\n",
    "from botocore.client import Config\n",
    "from ibm_botocore.client import Config\n",
    "from lightgbm import LGBMClassifier\n",
    "import ibm_boto3\n",
    "\n",
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get Cloud API Key from Global Pipeline Parameters\n",
    "CLOUD_API_KEY = os.getenv('cloud_api_key')\n",
    "\n",
    "# At this point, the filename of the binary is hardcoded.\n",
    "# With increasing complexity of your MLOps flow, you may want to add the filename as a pipeline parameter.\n",
    "FILENAME = \"model_pipeline.pkl\"\n",
    "\n",
    "## Retrieve cos credentials from pipeline parameters\n",
    "import json\n",
    "\n",
    "# Get json from environment and convert to string\n",
    "project_cos_credentials = json.loads(os.environ['project_cos_credentials'])\n",
    "mlops_cos_credentials = json.loads(os.getenv('mlops_cos_credentials'))\n",
    "\n",
    "## PROJECT COS\n",
    "AUTH_ENDPOINT = project_cos_credentials['AUTH_ENDPOINT']\n",
    "ENDPOINT_URL = project_cos_credentials['ENDPOINT_URL']\n",
    "API_KEY_COS = project_cos_credentials['API_KEY']\n",
    "# BUCKET_PROJECT_COS = project_cos_credentials['BUCKET']\n",
    "\n",
    "## MLOPS COS\n",
    "ENDPOINT_URL_MLOPS = mlops_cos_credentials['ENDPOINT_URL']\n",
    "API_KEY_MLOPS = mlops_cos_credentials['API_KEY']\n",
    "CRN_MLOPS = mlops_cos_credentials['CRN']\n",
    "BUCKET_MLOPS = mlops_cos_credentials['BUCKET']\n",
    "\n",
    "cos = ibm_boto3.resource(service_name='s3',\n",
    "                         ibm_api_key_id=API_KEY_MLOPS,\n",
    "                         ibm_service_instance_id=CRN_MLOPS,\n",
    "                         ibm_auth_endpoint=AUTH_ENDPOINT,\n",
    "                         config=Config(signature_version='oauth'),\n",
    "                         endpoint_url=ENDPOINT_URL_MLOPS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_model(key, filename):\n",
    "    download_file_cos(key, filename)\n",
    "    with open(filename, \"rb\") as f:\n",
    "        artifact = pickle.load(f)\n",
    "    return artifact\n",
    "\n",
    "def read_data_from_mlops_cos(key):\n",
    "    def __iter__(self): return 0\n",
    "\n",
    "    MLOPS_DATA_STORE_client = ibm_boto3.client(\n",
    "        service_name='s3',\n",
    "        ibm_api_key_id=API_KEY_MLOPS,\n",
    "        ibm_service_instance_id=CRN_MLOPS,\n",
    "        ibm_auth_endpoint=AUTH_ENDPOINT,\n",
    "        config=Config(signature_version='oauth'),\n",
    "        endpoint_url=ENDPOINT_URL_MLOPS)\n",
    "\n",
    "    body = MLOPS_DATA_STORE_client.get_object(Bucket=BUCKET_MLOPS, Key=key)['Body']\n",
    "    # add missing __iter__ method, so pandas accepts body as file-like object\n",
    "    if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType(__iter__, body)\n",
    "\n",
    "    gcf_df = pd.read_csv(body)\n",
    "    return gcf_df\n",
    "\n",
    "\n",
    "def download_file_cos(local_file_name, key):\n",
    "    cos = ibm_boto3.client(service_name='s3',\n",
    "                           ibm_api_key_id=API_KEY_MLOPS,\n",
    "                           ibm_service_instance_id=CRN_MLOPS,\n",
    "                           ibm_auth_endpoint=AUTH_ENDPOINT,\n",
    "                           config=Config(signature_version='oauth'),\n",
    "                           endpoint_url=ENDPOINT_URL_MLOPS)\n",
    "    try:\n",
    "        res = cos.download_file(Bucket=BUCKET_MLOPS, Key=key, Filename=local_file_name)\n",
    "    except Exception as e:\n",
    "        print(Exception, e)\n",
    "    else:\n",
    "        print('File Downloaded')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model_pipeline = load_model(FILENAME, FILENAME)\n",
    "\n",
    "# Download test_data from cos\n",
    "test_data = read_data_from_mlops_cos('test_tfr.csv')\n",
    "\n",
    "# Drop only 'Risk'\n",
    "y_test = test_data[test_data.columns[-1]]\n",
    "X_test = test_data.drop(list(test_data.columns)[-1:], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_input_columns = len(X_test.columns)\n",
    "n_model_columns = model_pipeline.n_features_in_\n",
    "\n",
    "input_columns = set(X_test.columns)\n",
    "model_columns = set(model_pipeline.steps[0][1].feature_names_in_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params['n_columns_input_vs_expected'] = (n_input_columns, n_model_columns)\n",
    "params['columns_input_vs_expected'] = (input_columns, model_columns)\n",
    "\n",
    "pipelines_client = WSPipelines.from_apikey(apikey=CLOUD_API_KEY)\n",
    "pipelines_client.store_results(params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}