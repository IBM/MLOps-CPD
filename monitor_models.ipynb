{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": [
                "### This Notebook will push a deployed model to OpenScale for monitoring its performance on payload data\n",
                "\n",
                "### This will also configure Explainability, Fairness and Drift with appropriate thresholds."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### The following cell is a way to get the utility script required for this notebook. \n",
                "Since IBM CPD SaaS doesn't have a filesystem, this is the only reliable way to get scripts on the cloud environment. \n",
                "```\n",
                "!rm -rf MLOps-CPD && git clone --quiet -b master https://github.com/IBM/MLOps-CPD.git\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The code was removed by Watson Studio for sharing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from datetime import datetime\n",
                "\n",
                "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator,BearerTokenAuthenticator\n",
                "from ibm_watson_openscale import *\n",
                "from ibm_watson_openscale.supporting_classes.enums import *\n",
                "from ibm_watson_openscale.supporting_classes import *\n",
                "from ibm_watson_machine_learning import APIClient as wmlapiclient\n",
                "from ibm_watson_studio_pipelines import WSPipelines\n",
                "from ibm_aigov_facts_client import AIGovFactsClient\n",
                "from botocore.client import Config\n",
                "from ibm_watson_openscale.data_sets import DataSetTypes, TargetTypes\n",
                "from ibm_watson_openscale.supporting_classes.payload_record import PayloadRecord\n",
                "import ibm_boto3\n",
                "import pandas as pd\n",
                "import json"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## DECLARE PIPELINE ENV VARIABLES"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CLOUD_API_KEY = os.getenv(\"cloud_api_key\")\n",
                "SPACE_ID = os.getenv(\"space_id\")\n",
                "MODEL_NAME = os.getenv(\"model_name\")\n",
                "DEPLOYMENT_NAME = os.getenv(\"deployment_name\")\n",
                "\n",
                "data_mart_id = os.getenv(\"data_mart_id\")\n",
                "service_provider_id = os.getenv(\"service_provider_id\")\n",
                "\n",
                "model_id = os.getenv(\"model_id\")\n",
                "deployment_id = os.getenv(\"deployment_id\")\n",
                "project_id = os.environ['PROJECT_ID']\n",
                "training_file_name = os.environ['training_data_reference_file']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Below hidden cells were for debugging"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The code was removed by Watson Studio for sharing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The code was removed by Watson Studio for sharing."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## CREDENTIALS"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load the validated training and test data from IBM COS \n",
                "\n",
                "```\n",
                "## PROJECT COS \n",
                "AUTH_ENDPOINT = \"https://iam.cloud.ibm.com/oidc/token\"\n",
                "ENDPOINT_URL = \"https://s3.private.us.cloud-object-storage.appdomain.cloud\"\n",
                "API_KEY_COS = \"xxx\"\n",
                "BUCKET_PROJECT_COS = \"mlops-donotdelete-pr-qxxcecxi1dtw94\"\n",
                "\n",
                "\n",
                "##MLOPS COS\n",
                "ENDPOINT_URL_MLOPS = \"https://s3.jp-tok.cloud-object-storage.appdomain.cloud\"\n",
                "API_KEY_MLOPS = \"xxx\"\n",
                "CRN_MLOPS = \"xxx\"\n",
                "BUCKET_MLOPS  = \"mlops-asset\"\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The code was removed by Watson Studio for sharing."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Authenticate and Instantiate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "authenticator = IAMAuthenticator(apikey=CLOUD_API_KEY)\n",
                "wos_client = APIClient(authenticator=authenticator,service_instance_id=data_mart_id)\n",
                "wos_client.version"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def read_data_from_mlops_cos(key,json=False):\n",
                "    def __iter__(self): return 0\n",
                "    MLOPS_DATA_STORE_client = ibm_boto3.client(\n",
                "        service_name='s3',\n",
                "        ibm_api_key_id=API_KEY_MLOPS,\n",
                "        ibm_service_instance_id=CRN_MLOPS,\n",
                "        ibm_auth_endpoint=AUTH_ENDPOINT,\n",
                "        config=Config(signature_version='oauth'),\n",
                "        endpoint_url=ENDPOINT_URL_MLOPS)\n",
                "\n",
                "    body = MLOPS_DATA_STORE_client.get_object(Bucket=BUCKET_MLOPS, Key=key)['Body']\n",
                "    # add missing __iter__ method, so pandas accepts body as file-like object\n",
                "    if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
                "    if json:\n",
                "        gcf_df = body\n",
                "    else:\n",
                "        gcf_df = pd.read_csv(body)\n",
                "    return gcf_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "service_credentials = {\n",
                "                  \"apikey\": CLOUD_API_KEY,\n",
                "                  \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n",
                "               }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Add service provider"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "WML_CREDENTIALS = {\n",
                "                   \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
                "                   \"apikey\": CLOUD_API_KEY\n",
                "            }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "wos_client.service_providers.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Determine if the deployment is in Prod Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "service_providers = wos_client.service_providers.list().result.service_providers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Check the tag for the service provider"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PROD_DEPLOYMENT = False\n",
                "for service_provider in service_providers:\n",
                "    deployment_space_id = service_provider.entity.deployment_space_id\n",
                "    if deployment_space_id == SPACE_ID and service_provider.entity.operational_space_id == \"production\":\n",
                "        PROD_DEPLOYMENT = True\n",
                "print('The deployed model is in production environment:', PROD_DEPLOYMENT)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Remove existing credit risk subscriptions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wml_client = wmlapiclient(WML_CREDENTIALS)\n",
                "wml_client.set.default_space(SPACE_ID)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wml_client.repository.list()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "subscriptions = wos_client.subscriptions.list().result.subscriptions\n",
                "for subscription in subscriptions:\n",
                "    sub_model_id = subscription.entity.asset.asset_id\n",
                "    if sub_model_id == model_id:\n",
                "        wos_client.subscriptions.delete(subscription.metadata.id)\n",
                "        print(\"Deleted existing subscription for model\", sub_model_id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Get Model Details"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# # DEPLOYMENT_NAME ='GCR_Model_DEPLOYMENT_NAME'\n",
                "\n",
                "# #deployment_id = [model['metadata']['id'] for model in wml_client.deployments.get_details()['resources'] if model['metadata']['name']==DEPLOYMENT_NAME][-1]\n",
                "\n",
                "deployment_id\n",
                "\n",
                "deployment_url = [deployment[\"entity\"][\"status\"][\"online_url\"][\"url\"] for deployment in wml_client.deployments.get_details()['resources'] if deployment['metadata']['name']==DEPLOYMENT_NAME][-1]\n",
                "print(deployment_id,deployment_url)\n",
                "\n",
                "\n",
                "published_model_details = wml_client.repository.get_details(model_id)\n",
                "published_model_details\n",
                "\n",
                "# wml_client.deployments.get_details()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Prepare Eval Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_data = read_data_from_mlops_cos('test_tfr.csv')\n",
                "test_data = test_data.drop('Risk',axis=1)\n",
                "features = test_data.columns.tolist()\n",
                "categorical = test_data.select_dtypes('O').columns.tolist()\n",
                "categorical, features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create the model subscription in OpenScale"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "asset = Asset(\n",
                "    asset_id=model_id,\n",
                "    url=deployment_url,\n",
                "    asset_type=AssetTypes.MODEL,\n",
                "    input_data_type=InputDataType.STRUCTURED,\n",
                "    problem_type=ProblemType.BINARY_CLASSIFICATION,\n",
                "    name=MODEL_NAME\n",
                ")\n",
                "asset_deployment = AssetDeploymentRequest(\n",
                "    deployment_id=deployment_id,\n",
                "    name=DEPLOYMENT_NAME,\n",
                "    deployment_type=DeploymentTypes.ONLINE,\n",
                "    url=deployment_url\n",
                ")\n",
                "training_data_reference = TrainingDataReference(\n",
                "    type=\"cos\",\n",
                "    location=COSTrainingDataReferenceLocation(\n",
                "        bucket=BUCKET_MLOPS,\n",
                "        file_name=training_file_name\n",
                "    ),\n",
                "    connection=COSTrainingDataReferenceConnection.from_dict(\n",
                "        {\n",
                "            \"resource_instance_id\": CRN_MLOPS,\n",
                "            \"url\": ENDPOINT_URL_MLOPS,\n",
                "            \"api_key\": API_KEY_MLOPS,\n",
                "            \"iam_url\": \"https://iam.bluemix.net/oidc/token\"\n",
                "        }\n",
                "    )\n",
                ")\n",
                "\n",
                "asset_properties_request = AssetPropertiesRequest(\n",
                "    label_column=\"Risk\",\n",
                "    probability_fields=[\"probability\"],\n",
                "    prediction_field=\"prediction\",\n",
                "    feature_fields= features,\n",
                "    categorical_fields= categorical,\n",
                "    training_data_reference=training_data_reference,\n",
                "    #training_data_schema=SparkStruct.from_dict(model_asset_details_from_deployment[\"entity\"][\"asset_properties\"][\"training_data_schema\"])\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": [
                "subscription_details = wos_client.subscriptions.add(\n",
                "        data_mart_id=data_mart_id,\n",
                "        service_provider_id=service_provider_id,\n",
                "        asset=asset,\n",
                "        deployment=asset_deployment,\n",
                "        asset_properties=asset_properties_request,background_mode = False).result\n",
                "subscription_id = subscription_details.metadata.id\n",
                "print(subscription_details)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Verify the Subscription Registration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wos_client.subscriptions.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Get Payload Data ID"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "time.sleep(5)\n",
                "payload_data_set_id = None\n",
                "payload_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, \n",
                "                                                target_target_id=subscription_id, \n",
                "                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n",
                "if payload_data_set_id is None:\n",
                "    print(\"Payload data set not found. Please check subscription status.\")\n",
                "else:\n",
                "    print(\"Payload data set id:\", payload_data_set_id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Score the WML Endpoint"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "payload_data = read_data_from_mlops_cos('test_tfr.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "payload_data = payload_data.drop('Risk',axis=1)\n",
                "fields = payload_data.columns.tolist()\n",
                "values = [payload_data.values.tolist()[0]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "payload_scoring = {\"input_data\": [{\"fields\": fields, \"values\": values}]}\n",
                "json.dumps(payload_scoring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions = wml_client.deployments.score(deployment_id, payload_scoring)\n",
                "\n",
                "print(\"Single record scoring result:\", \"\\n fields:\", predictions[\"predictions\"][0][\"fields\"], \"\\n values: \", predictions[\"predictions\"][0][\"values\"][0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Check if the Payload logging has taken place"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import uuid\n",
                "from ibm_watson_openscale.supporting_classes.payload_record import PayloadRecord\n",
                "time.sleep(5)\n",
                "pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
                "print(\"Number of records in the payload logging table: {}\".format(pl_records_count))\n",
                "if pl_records_count == 0:\n",
                "    print(\"Payload logging did not happen, performing explicit payload logging.\")\n",
                "    wos_client.data_sets.store_records(data_set_id=payload_data_set_id, request_body=[PayloadRecord(\n",
                "                   scoring_id=str(uuid.uuid4()),\n",
                "                   request=payload_scoring,\n",
                "                   response={\"fields\": predictions['predictions'][0]['fields'], \"values\":predictions['predictions'][0]['values']},\n",
                "                   response_time=460\n",
                "               )],background_mode = False)\n",
                "    time.sleep(5)\n",
                "    pl_records_count = wos_client.data_sets.get_records_count(payload_data_set_id)\n",
                "    print(\"Number of records in the payload logging table: {}\".format(pl_records_count))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Enable Monitors for the Subscription"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Quality Monitor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "\n",
                "time.sleep(10)\n",
                "target = Target(\n",
                "        target_type=TargetTypes.SUBSCRIPTION,\n",
                "        target_id=subscription_id\n",
                ")\n",
                "parameters = {\n",
                "    \"min_feedback_data_size\": 100\n",
                "}\n",
                "thresholds = [\n",
                "                {\n",
                "                    \"metric_id\": \"area_under_roc\",\n",
                "                    \"type\": \"lower_limit\",\n",
                "                    \"value\": .60\n",
                "                }\n",
                "            ]\n",
                "quality_monitor_details = wos_client.monitor_instances.create(\n",
                "    data_mart_id=data_mart_id,\n",
                "    background_mode=False,\n",
                "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.QUALITY.ID,\n",
                "    target=target,\n",
                "    parameters=parameters,\n",
                "    thresholds=thresholds\n",
                ").result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "quality_monitor_instance_id = quality_monitor_details.metadata.id\n",
                "quality_monitor_instance_id"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Get the Feedback Data for Monitoring"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pprint import pprint\n",
                "feedback_data = read_data_from_mlops_cos(\"hold_out_feedback_101.json\",json=True)\n",
                "feedback_data = json.loads(feedback_data.read())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "feedback_dataset_id = None\n",
                "feedback_dataset = wos_client.data_sets.list(type=DataSetTypes.FEEDBACK, \n",
                "                                                target_target_id=subscription_id, \n",
                "                                                target_target_type=TargetTypes.SUBSCRIPTION).result\n",
                "\n",
                "feedback_dataset_id = feedback_dataset.data_sets[0].metadata.id\n",
                "if feedback_dataset_id is None:\n",
                "    print(\"Feedback data set not found. Please check quality monitor status.\")\n",
                "else:\n",
                "    print(\"Feedback data set id:\", feedback_dataset_id)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wos_client.data_sets.store_records(feedback_dataset_id, request_body=feedback_data, background_mode=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "feedback_records_count = wos_client.data_sets.get_records_count(feedback_dataset_id)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert feedback_records_count >= 100, \"Minimum feedback data size is set to 100, please add more feedback data!\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "time.sleep(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run Quality Monitor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#pipeline metrics\n",
                "openscale_metrics ={}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Enable Fairness"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wos_client.monitor_instances.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target = Target(\n",
                "    target_type=TargetTypes.SUBSCRIPTION,\n",
                "    target_id=subscription_id\n",
                "\n",
                ")\n",
                "parameters = {\n",
                "    \"features\": [\n",
                "        {\"feature\": \"Sex\",\n",
                "         \"majority\": ['male'],\n",
                "         \"minority\": ['female'],\n",
                "         \"threshold\": 0.95\n",
                "         },\n",
                "        {\"feature\": \"Age\",\n",
                "         \"majority\": [[26, 75]],\n",
                "         \"minority\": [[18, 25]],\n",
                "         \"threshold\": 0.95\n",
                "         }\n",
                "    ],\n",
                "    \"favourable_class\": [\"No Risk\"],\n",
                "    \"unfavourable_class\": [\"Risk\"],\n",
                "    \"min_records\": 100\n",
                "}\n",
                "\n",
                "fairness_monitor_details = wos_client.monitor_instances.create(\n",
                "    data_mart_id=data_mart_id,\n",
                "    background_mode=False,\n",
                "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.FAIRNESS.ID,\n",
                "    target=target,\n",
                "    parameters=parameters).result\n",
                "fairness_monitor_instance_id =fairness_monitor_details.metadata.id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "monitor_instances = wos_client.monitor_instances.list().result.monitor_instances\n",
                "for monitor_instance in monitor_instances:\n",
                "    monitor_def_id=monitor_instance.entity.monitor_definition_id\n",
                "    if monitor_def_id == \"drift\" and monitor_instance.entity.target.target_id == subscription_id:\n",
                "        wos_client.monitor_instances.delete(monitor_instance.metadata.id)\n",
                "        print('Deleted existing drift monitor instance with id: ', monitor_instance.metadata.id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Enable Drift"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target = Target(\n",
                "    target_type=TargetTypes.SUBSCRIPTION,\n",
                "    target_id=subscription_id\n",
                "\n",
                ")\n",
                "\n",
                "parameters = {\n",
                "    \"min_samples\": 100,\n",
                "    \"drift_threshold\": 0.1,\n",
                "    \"train_drift_model\": True,\n",
                "    \"enable_model_drift\": False,\n",
                "    \"enable_data_drift\": True\n",
                "}\n",
                "\n",
                "\n",
                "drift_monitor_details = wos_client.monitor_instances.create(\n",
                "    data_mart_id=data_mart_id,\n",
                "    background_mode=False,\n",
                "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.DRIFT.ID,\n",
                "    target=target,\n",
                "    parameters=parameters\n",
                ").result\n",
                "\n",
                "drift_monitor_instance_id = drift_monitor_details.metadata.id"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Enable Explainability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target = Target(\n",
                "    target_type=TargetTypes.SUBSCRIPTION,\n",
                "    target_id=subscription_id\n",
                ")\n",
                "parameters = {\n",
                "    \"enabled\": True\n",
                "}\n",
                "explain_monitor_details = wos_client.monitor_instances.create(\n",
                "    data_mart_id=data_mart_id,\n",
                "    background_mode=False,\n",
                "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.EXPLAINABILITY.ID,\n",
                "    target=target,\n",
                "    parameters=parameters\n",
                ").result\n",
                "\n",
                "explain_monitor_details.metadata.id"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Payload Log the data "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def pl_log(sub_id,request_data,response_data):\n",
                "    # Retrieve the id of the payload logging data set\n",
                "    SUBSCRIPTION_ID =sub_id\n",
                "    payload_logging_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, target_target_id=SUBSCRIPTION_ID, target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n",
                "\n",
                "    wos_client.data_sets.store_records(data_set_id=payload_logging_data_set_id, request_body=[PayloadRecord(request=request_data, response=response_data, response_time=460)])\n",
                "\n",
                "    print(\"Payload Logging Successful\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "payload_test_data = read_data_from_mlops_cos('test_tfr.csv')\n",
                "payload_test_data = payload_test_data.drop(\"Risk\",axis=1)\n",
                "\n",
                "fields = payload_test_data.columns.tolist()\n",
                "values = payload_test_data.values.tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "payload_scoring = {\"input_data\": [{\"fields\": fields, \"values\": values}]}\n",
                "predictions = wml_client.deployments.score(deployment_id, payload_scoring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pl_log(subscription_id,payload_scoring,predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "wos_client.data_sets.get_records_count(data_set_id=payload_data_set_id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Enable MRM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target = Target(\n",
                "    target_type=TargetTypes.SUBSCRIPTION,\n",
                "    target_id=subscription_id\n",
                ")\n",
                "parameters = {\n",
                "}\n",
                "mrm_monitor_details = wos_client.monitor_instances.create(\n",
                "    data_mart_id=data_mart_id,\n",
                "    background_mode=False,\n",
                "    monitor_definition_id='mrm',\n",
                "    target=target,\n",
                "    parameters=parameters\n",
                ").result\n",
                "\n",
                "mrm_instance_id = mrm_monitor_details.metadata.id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "test_data_mrm = read_data_from_mlops_cos('test_tfr.csv')\n",
                "test_data_mrm.to_csv(\"gcr_mrm.csv\", encoding=\"utf-8\", index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import requests\n",
                "def generate_access_token():\n",
                "    headers = {\n",
                "        \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
                "    }\n",
                "\n",
                "    data = (\n",
                "        f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={CLOUD_API_KEY}\"\n",
                "    )\n",
                "\n",
                "    response = requests.post(\"https://iam.cloud.ibm.com/identity/token\", headers=headers, data=data)\n",
                "\n",
                "    return response.json()[\"access_token\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# evaluation_tests = [\"fairness\", \"quality\", \"drift\"]\n",
                "# mrm_run_parameters = {\"on_demand_trigger\": True, \"evaluation_tests\": evaluation_tests, \"publish_fact\": \"true\"}\n",
                "# wos_client.monitor_instances.run(monitor_instance_id=mrm_instance_id, triggered_by=\"user\", background_mode=False, parameters=mrm_run_parameters)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Non-prod evaluations\n",
                "\n",
                "### Function to upload, evaluate and check the status of the evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def upload_and_evaluate(file_name, mrm_instance_id):\n",
                "    \n",
                "    print(\"Running upload and evaluate for {}\".format(file_name))\n",
                "    import json\n",
                "    import time\n",
                "    from datetime import datetime\n",
                "\n",
                "    status = None\n",
                "    monitoring_run_id = None\n",
                "    GET_UPLOAD_AND_EVALUATION_STATUS_RETRIES = 32\n",
                "    GET_UPLOAD_AND_EVALUATION_STATUS_INTERVAL = 10\n",
                "    \n",
                "    if file_name is not None:\n",
                "        \n",
                "        headers = {}\n",
                "        headers[\"Content-Type\"] = \"text/csv\"\n",
                "        headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
                "        \n",
                "        POST_EVALUATIONS_URL = service_credentials[\"url\"] + \"/openscale/{0}/v2/monitoring_services/mrm/monitor_instances/{1}/risk_evaluations?test_data_set_name={2}\".format(data_mart_id, mrm_instance_id, file_name)\n",
                "\n",
                "        with open(file_name) as file:\n",
                "            f = file.read()\n",
                "            b = bytearray(f, 'utf-8')\n",
                "        \n",
                "\n",
                "        response = requests.post(POST_EVALUATIONS_URL, data=bytes(b), headers=headers, verify=False)\n",
                "    \n",
                "        if response.ok is False:\n",
                "            print(\"Upload and evalaute for {0} failed with {1}: {2}\".format(file_name, response.status_code, response.reason))\n",
                "            return\n",
                "        \n",
                "        headers = {}\n",
                "        headers[\"Content-Type\"] = \"application/json\"\n",
                "        headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
                "\n",
                "        GET_EVALUATIONS_URL = service_credentials[\"url\"] + \"/openscale/{0}/v2/monitoring_services/mrm/monitor_instances/{1}/risk_evaluations\".format(data_mart_id, mrm_instance_id)\n",
                "        \n",
                "        for i in range(GET_UPLOAD_AND_EVALUATION_STATUS_RETRIES):\n",
                "        \n",
                "            response = requests.get(GET_EVALUATIONS_URL, headers=headers, verify=False)\n",
                "            if response.ok is False:\n",
                "                print(\"Getting status of upload and evalaute for {0} failed with {1}: {2}\".format(file_name, response.status_code, response.reason))\n",
                "                return\n",
                "\n",
                "            response = json.loads(response.text)\n",
                "            if \"metadata\" in response and \"id\" in response[\"metadata\"]:\n",
                "                monitoring_run_id = response[\"metadata\"][\"id\"]\n",
                "            if \"entity\" in response and \"status\" in response[\"entity\"]:\n",
                "                status = response[\"entity\"][\"status\"][\"state\"]\n",
                "            \n",
                "            if status is not None:\n",
                "                print(datetime.utcnow().strftime('%H:%M:%S'), status.lower())\n",
                "                if status.lower() in [\"finished\", \"completed\"]:\n",
                "                    break\n",
                "                elif \"error\" in status.lower():\n",
                "                    print(response)\n",
                "                    break\n",
                "\n",
                "            time.sleep(GET_UPLOAD_AND_EVALUATION_STATUS_INTERVAL)\n",
                "\n",
                "    return status, monitoring_run_id"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Run MRM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not PROD_DEPLOYMENT:\n",
                "    upload_and_evaluate(\"gcr_mrm.csv\", mrm_instance_id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Show the monitor metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not PROD_DEPLOYMENT:\n",
                "    time.sleep(5)\n",
                "    wos_client.monitor_instances.show_metrics(monitor_instance_id=fairness_monitor_instance_id)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not PROD_DEPLOYMENT:\n",
                "    time.sleep(5)\n",
                "    wos_client.monitor_instances.show_metrics(monitor_instance_id=drift_monitor_instance_id)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not PROD_DEPLOYMENT:\n",
                "    time.sleep(5)\n",
                "    wos_client.monitor_instances.show_metrics(monitor_instance_id=quality_monitor_instance_id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "###  Run all the monitors"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Quality"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# run_details = wos_client.monitor_instances.run(monitor_instance_id=quality_monitor_instance_id, background_mode=False).result\n",
                "\n",
                "# time.sleep(5)\n",
                "# wos_client.monitor_instances.show_metrics(monitor_instance_id=quality_monitor_instance_id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Fairness"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# run_details = wos_client.monitor_instances.run(monitor_instance_id=fairness_monitor_instance_id, background_mode=False)\n",
                "# time.sleep(5)\n",
                "# wos_client.monitor_instances.show_metrics(monitor_instance_id=fairness_monitor_instance_id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Drift"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# drift_run_details = wos_client.monitor_instances.run(monitor_instance_id=drift_monitor_instance_id, background_mode=False)\n",
                "# time.sleep(5)\n",
                "# wos_client.monitor_instances.show_metrics(monitor_instance_id=drift_monitor_instance_id)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Gather results for the last run "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "openscale_metrics ={}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_monitor_metrics(config, deployment_name, monitor_type):\n",
                "    wos_client = config[\"wos_client\"]\n",
                "    dict_monitor_instances = get_monitor_instances_by_deployment_name(config=config, deployment_name=deployment_name)\n",
                "    start_time = datetime.now() - timedelta(days=7)\n",
                "    end_time = datetime.now()\n",
                "\n",
                "    monitor_instance_id = dict_monitor_instances[monitor_type]\n",
                "    runs = wos_client.monitor_instances.runs.list(monitor_instance_id=monitor_instance_id).result.runs\n",
                "    measurements = ibm_watson_openscale.base_classes.watson_open_scale_v2.Measurements(watson_open_scale=wos_client.monitor_instances._ai_client)\n",
                "    for run in runs:\n",
                "        run_id = run.to_dict()[\"metadata\"][\"id\"]\n",
                "        response = measurements.list(monitor_instance_id=monitor_instance_id, start=start_time, end=end_time, run_id=run_id)\n",
                "        metrics = response.result.to_dict()[\"measurements\"][0][\"entity\"][\"values\"][0][\"metrics\"]\n",
                "        return metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "openscale_metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# pipelines_client = WSPipelines.from_apikey(apikey=\"dhUSiBv8cezmf1NsfDX8ngsi1ruwf2DUE00bwpoHUlLk\")\n",
                "# pipelines_client.store_results(openscale_metrics)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# wos_client.data_sets.show_records(data_set_id=feedback_dataset_id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Prod\n",
                "\n",
                "## Fetch all monitor instances"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get the monitor instances IDs from OpenScale \n",
                "# Note: only run this if the monitor instances were already created before running this notebook\n",
                "\n",
                "# headers = {}\n",
                "# headers[\"Content-Type\"] = \"application/json\"\n",
                "# headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
                "\n",
                "# MONITOR_INSTANCES_URL = \"https://api.aiopenscale.cloud.ibm.com/openscale/{0}/v2/monitor_instances?target.target_id={1}&target.target_type=subscription\".format(data_mart_id, subscription_id)\n",
                "# print(MONITOR_INSTANCES_URL)\n",
                "\n",
                "# response = requests.get(MONITOR_INSTANCES_URL, headers=headers)\n",
                "# monitor_instances = response.json()[\"monitor_instances\"]\n",
                "\n",
                "# drift_monitor_instance_id = None\n",
                "# quality_monitor_instance_id = None\n",
                "# fairness_monitor_instance_id= None\n",
                "# mrm_monitor_instance_id = None\n",
                "\n",
                "# if monitor_instances is not None:\n",
                "#     for monitor_instance in monitor_instances:\n",
                "#         if \"entity\" in monitor_instance and \"monitor_definition_id\" in monitor_instance[\"entity\"]:\n",
                "#             monitor_name = monitor_instance[\"entity\"][\"monitor_definition_id\"]\n",
                "#             if \"metadata\" in monitor_instance and \"id\" in monitor_instance[\"metadata\"]:\n",
                "#                 id = monitor_instance[\"metadata\"][\"id\"]\n",
                "#                 if monitor_name == \"drift\":\n",
                "#                     drift_monitor_instance_id = id\n",
                "#                 elif monitor_name == \"fairness\":\n",
                "#                     fairness_monitor_instance_id = id\n",
                "#                 elif monitor_name == \"quality\":\n",
                "#                     quality_monitor_instance_id = id\n",
                "#                 elif monitor_name == \"mrm\":\n",
                "#                     mrm_instance_id = id"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Quality monitor instance id - {0}\".format(quality_monitor_instance_id))\n",
                "print(\"Fairness monitor instance id - {0}\".format(fairness_monitor_instance_id))\n",
                "print(\"Drift monitor instance id - {0}\".format(drift_monitor_instance_id))\n",
                "print(\"MRM monitor instance id - {0}\".format(mrm_instance_id))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "## Function to get the monitoring run details\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_monitoring_run_details(monitor_instance_id, monitoring_run_id):\n",
                "    \n",
                "    headers = {}\n",
                "    headers[\"Content-Type\"] = \"application/json\"\n",
                "    headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
                "    \n",
                "    MONITORING_RUNS_URL = \"https://api.aiopenscale.cloud.ibm.com/openscale/{0}/v2/monitor_instances/{1}/runs/{2}\".format(data_mart_id, monitor_instance_id, monitoring_run_id)\n",
                "    response = requests.get(MONITORING_RUNS_URL, headers=headers, verify=False)\n",
                "    return response.json()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run on-demand MRM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if PROD_DEPLOYMENT:\n",
                "    headers = {}\n",
                "    headers[\"Content-Type\"] = \"application/json\"\n",
                "    headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
                "\n",
                "    if mrm_instance_id is not None:\n",
                "        MONITOR_RUN_URL =\"https://api.aiopenscale.cloud.ibm.com/openscale/{0}/v2/monitor_instances/{1}/runs\".format(data_mart_id, mrm_instance_id)\n",
                "        payload = {\n",
                "            \"triggered_by\": \"user\"\n",
                "        }\n",
                "        print(\"Triggering MRM computation with {}\".format(MONITOR_RUN_URL))\n",
                "        response = requests.post(MONITOR_RUN_URL, json=payload, headers=headers, verify=False)\n",
                "        json_data = response.json()\n",
                "        print()\n",
                "        print(json_data)\n",
                "        print()\n",
                "        if \"metadata\" in json_data and \"id\" in json_data[\"metadata\"]:\n",
                "            mrm_monitoring_run_id = json_data[\"metadata\"][\"id\"]\n",
                "        print(\"Done triggering MRM computation\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if PROD_DEPLOYMENT:\n",
                "    mrm_run_status = None\n",
                "    while mrm_run_status != 'finished':\n",
                "        monitoring_run_details = get_monitoring_run_details(mrm_instance_id, mrm_monitoring_run_id)\n",
                "        mrm_run_status = monitoring_run_details[\"entity\"][\"status\"][\"state\"]\n",
                "        if mrm_run_status == \"error\":\n",
                "            print(monitoring_run_details)\n",
                "            break\n",
                "        if mrm_run_status != 'finished':\n",
                "            print(datetime.utcnow().strftime('%H:%M:%S'), mrm_run_status)\n",
                "            time.sleep(10)\n",
                "    print(mrm_run_status)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run on-demand Quality"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if PROD_DEPLOYMENT:\n",
                "    headers = {}\n",
                "    headers[\"Content-Type\"] = \"application/json\"\n",
                "    headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
                "\n",
                "    if quality_monitor_instance_id is not None:\n",
                "        MONITOR_RUN_URL = \"https://api.aiopenscale.cloud.ibm.com/openscale/{0}/v2/monitor_instances/{1}/runs\".format(data_mart_id, quality_monitor_instance_id)\n",
                "        payload = {\n",
                "            \"triggered_by\": \"user\"\n",
                "        }\n",
                "        print(\"Triggering Quality computation with {}\".format(MONITOR_RUN_URL))\n",
                "        response = requests.post(MONITOR_RUN_URL, json=payload, headers=headers, verify=False)\n",
                "        json_data = response.json()\n",
                "        print()\n",
                "        print(json_data)\n",
                "        print()\n",
                "        if \"metadata\" in json_data and \"id\" in json_data[\"metadata\"]:\n",
                "            quality_monitoring_run_id = json_data[\"metadata\"][\"id\"]\n",
                "        print(\"Done triggering Quality computation\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if PROD_DEPLOYMENT:\n",
                "    quality_run_status = None\n",
                "    while quality_run_status != 'finished':\n",
                "        monitoring_run_details = get_monitoring_run_details(quality_monitor_instance_id, quality_monitoring_run_id)\n",
                "        quality_run_status = monitoring_run_details[\"entity\"][\"status\"][\"state\"]\n",
                "        if quality_run_status == \"error\":\n",
                "            print(monitoring_run_details)\n",
                "            break\n",
                "        if quality_run_status != 'finished':\n",
                "            print(datetime.utcnow().strftime('%H:%M:%S'), quality_run_status)\n",
                "            time.sleep(10)\n",
                "    print(quality_run_status)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "## Run on-demand Fairness\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if PROD_DEPLOYMENT:\n",
                "    headers = {}\n",
                "    headers[\"Content-Type\"] = \"application/json\"\n",
                "    headers[\"Authorization\"] = \"Bearer {}\".format(generate_access_token())\n",
                "\n",
                "    if fairness_monitor_instance_id is not None:\n",
                "        MONITOR_RUN_URL = \"https://api.aiopenscale.cloud.ibm.com/openscale/{0}/v2/monitor_instances/{1}/runs\".format(data_mart_id, fairness_monitor_instance_id)\n",
                "        payload = {\n",
                "            \"triggered_by\": \"user\"\n",
                "        }\n",
                "        print(\"Triggering fairness computation with {}\".format(MONITOR_RUN_URL))\n",
                "        response = requests.post(MONITOR_RUN_URL, json=payload, headers=headers, verify=False)\n",
                "        json_data = response.json()\n",
                "        print()\n",
                "        print(json_data)\n",
                "        print()\n",
                "        if \"metadata\" in json_data and \"id\" in json_data[\"metadata\"]:\n",
                "            fairness_monitor_run_id = json_data[\"metadata\"][\"id\"]\n",
                "        print(\"Done triggering fairness computation\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if PROD_DEPLOYMENT:\n",
                "    fairness_run_status = None\n",
                "    while fairness_run_status != 'finished':\n",
                "        monitoring_run_details = get_monitoring_run_details(fairness_monitor_instance_id, fairness_monitor_run_id)\n",
                "        fairness_run_status = monitoring_run_details[\"entity\"][\"status\"][\"state\"]\n",
                "        if fairness_run_status == \"error\":\n",
                "            print(monitoring_run_details)\n",
                "            break\n",
                "        if fairness_run_status != 'finished':\n",
                "            print(datetime.utcnow().strftime('%H:%M:%S'), fairness_run_status)\n",
                "            time.sleep(10)\n",
                "    print(fairness_run_status)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8 (main, Oct 21 2022, 22:22:30) [Clang 14.0.0 (clang-1400.0.29.202)]"
        },
        "vscode": {
            "interpreter": {
                "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
